{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eyaler/LordTubeMaster/blob/main/models/teed/teed2onnx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nceGxlYDjxnu"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: 'UTF-8'\n",
        "\n",
        "%cd /content\n",
        "!git clone --depth=1 https://github.com/eyaler/TEED\n",
        "!pip install kornia==0.7.3\n",
        "!pip install onnx==1.16.2\n",
        "!pip install numpy==1.26.4\n",
        "!pip install onnxruntime-gpu==1.18.0 --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/\n",
        "!pip install onnxconverter-common==1.14.0 --no-deps\n",
        "!wget -nc https://upload.wikimedia.org/wikipedia/commons/a/a9/Hong_Kong_Night_view.jpg -O TEED/data/image.jpg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Export to ONNX (with pre/post-processing)\n",
        "\n",
        "%cd /content/TEED\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from ted import TED\n",
        "\n",
        "\n",
        "device = 'cuda'\n",
        "\n",
        "\n",
        "class MyTED(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.ted_model = TED()\n",
        "        self.ted_model.load_state_dict(torch.load('checkpoints/BIPED/7/7_model.pth', map_location=device))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 3, 1, 2).to(torch.float32)\n",
        "        h, w = x.shape[2:]\n",
        "        pad = F.pad(x, (0, (w//4+1)*4 - w, 0, (h//4+1)*4 - h))\n",
        "        block_cat = self.ted_model(pad)[-1]\n",
        "        crop = block_cat.squeeze()[:h, :w]\n",
        "        sigmoid = torch.sigmoid(crop)\n",
        "        minimum = sigmoid.min()\n",
        "        return (sigmoid-minimum) * 255 / (sigmoid.max()-minimum+1e-12)\n",
        "\n",
        "\n",
        "model = MyTED().to(device)\n",
        "\n",
        "dummy_input = torch.randint(0, 255, (1, 1080, 1920, 3), dtype=torch.uint8, device=device)\n",
        "\n",
        "torch.onnx.export(model,\n",
        "                  (dummy_input),\n",
        "                  'teed.onnx',\n",
        "                  input_names=['input'],\n",
        "                  output_names=['output'],\n",
        "                  dynamic_axes=dict(input={1 : 'height', 2: 'width'}, output={0 : 'height', 1: 'width'}),\n",
        "                 )\n",
        "\n",
        "\n",
        "import onnx\n",
        "from onnxconverter_common import float16\n",
        "\n",
        "\n",
        "model = onnx.load('teed.onnx')\n",
        "model16 = float16.convert_float_to_float16(model, keep_io_types=True)\n",
        "onnx.save_model(model16, 'teed16.onnx')"
      ],
      "metadata": {
        "id": "LqgJEh9Aj8cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ONNX Runtime Python\n",
        "\n",
        "%cd /content/TEED\n",
        "\n",
        "\n",
        "from time import time\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import onnxruntime as ort\n",
        "\n",
        "bench_iters = 100\n",
        "image_path = 'data/image.jpg'\n",
        "image = cv2.imread(image_path, cv2.IMREAD_COLOR)[..., ::-1]\n",
        "# image = cv2.resize(image, (1917, 1077))  # Odd dimensions for debugging\n",
        "image = image[None, :]\n",
        "\n",
        "ort.set_default_logger_severity(0)\n",
        "ort_session = ort.InferenceSession('teed16.onnx', providers=['CUDAExecutionProvider'])\n",
        "\n",
        "bench_iters = max(bench_iters, 2)\n",
        "for i in range(bench_iters):\n",
        "  outputs = ort_session.run(None, {'input': image})\n",
        "  output = np.dstack(outputs[:1] * 3)\n",
        "  if not i:\n",
        "    start_time = time()\n",
        "print(f'{outputs[0].shape[1]}x{outputs[0].shape[0]} {(time()-start_time) * 1000 / (bench_iters-1) :.0f}ms/iter')\n",
        "\n",
        "cv2.imwrite('out.jpg', output)\n",
        "cv2_imshow(output)"
      ],
      "metadata": {
        "id": "DqzOdcMznL6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ln -sf /usr/local/share/jupyter/nbextensions /nbextensions\n",
        "!cp /content/TEED/teed.onnx /nbextensions/teed.onnx\n",
        "!cp /content/TEED/teed16.onnx /nbextensions/teed16.onnx\n",
        "!cp /content/TEED/data/image.jpg /nbextensions/image.jpg"
      ],
      "metadata": {
        "id": "FJT92jT0vP6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ONNX Runtime Wasm\n",
        "\n",
        "%%html\n",
        "<p id=\"stats\"><p>\n",
        "<canvas id=\"canvas\" style=\"width: 100%\"></canvas>\n",
        "<script type=\"module\">\n",
        "  import * as ort from 'https://cdn.jsdelivr.net/npm/onnxruntime-web@1.18.0/dist/esm/ort.wasm-core.min.js'\n",
        "  ort.env.wasm.wasmPaths = 'https://cdn.jsdelivr.net/npm/onnxruntime-web@1.18.0/dist/'\n",
        "\n",
        "  const teed = await ort.InferenceSession.create('/nbextensions/teed.onnx')\n",
        "\n",
        "  let bench_iters = 10\n",
        "\n",
        "  const ctx = canvas.getContext('2d')\n",
        "  const img = new Image()\n",
        "  img.crossOrigin = 'anonymous'\n",
        "\n",
        "  async function predict() {\n",
        "    const w = canvas.width = img.width\n",
        "    const h = canvas.height = img.height\n",
        "    ctx.drawImage(img, 0, 0)\n",
        "    const rgba = ctx.getImageData(0, 0, w, h).data\n",
        "    const rgba_out = rgba.slice()\n",
        "    ctx.clearRect(0, 0, w, h)\n",
        "    let start_time\n",
        "    bench_iters = Math.max(bench_iters, 2)\n",
        "    for (let n = 0; n < bench_iters; n++) {\n",
        "      const bgr = new Uint8Array(h * w * 3)\n",
        "      for (let i = 0; i < bgr.length; i++)\n",
        "        bgr[i] = rgba[(i/3|0)*4 + 2 - i%3]\n",
        "      const result = await teed.run({input: new ort.Tensor(bgr, [1, h, w, 3])})\n",
        "      for (let i = 0; i < result.output.data.length; i++)\n",
        "        rgba_out[i * 4] = rgba_out[i*4 + 1] = rgba_out[i*4 + 2] = result.output.data[i]\n",
        "      if (!n)\n",
        "        start_time = performance.now()\n",
        "    }\n",
        "    stats.textContent = w + 'x' + h + ' ' + ((performance.now()-start_time)/(bench_iters-1)|0) + 'ms/iter'\n",
        "    ctx.putImageData(new ImageData(rgba_out, w, h), 0, 0)\n",
        "  }\n",
        "\n",
        "  img.addEventListener('load', () => predict())\n",
        "  img.src = '/nbextensions/image.jpg'\n",
        "</script>"
      ],
      "metadata": {
        "id": "UB4Tpqrgn_J9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ONNX Runtime WebGPU\n",
        "\n",
        "%%html\n",
        "<p id=\"stats\"><p>\n",
        "<canvas id=\"canvas\" style=\"width: 100%\"></canvas>\n",
        "<script type=\"module\">\n",
        "  import * as ort from 'https://cdn.jsdelivr.net/npm/onnxruntime-web@1.18.0/dist/esm/ort.webgpu.min.js'\n",
        "  ort.env.wasm.wasmPaths = 'https://cdn.jsdelivr.net/npm/onnxruntime-web@1.18.0/dist/'\n",
        "\n",
        "  let teed\n",
        "  try {\n",
        "    teed = await ort.InferenceSession.create('/nbextensions/teed16.onnx', {executionProviders: ['webgpu']})\n",
        "  } catch (e) {\n",
        "    if (e.message.includes('webgpu'))\n",
        "      stats.textContent = 'WebGPU not supported.'\n",
        "    throw e\n",
        "  }\n",
        "\n",
        "  let bench_iters = 100\n",
        "\n",
        "  const ctx = canvas.getContext('2d')\n",
        "  const img = new Image()\n",
        "  img.crossOrigin = 'anonymous'\n",
        "\n",
        "  async function predict() {\n",
        "    const w = canvas.width = img.width\n",
        "    const h = canvas.height = img.height\n",
        "    ctx.drawImage(img, 0, 0)\n",
        "    const rgba = ctx.getImageData(0, 0, w, h).data\n",
        "    const rgba_out = rgba.slice()\n",
        "    ctx.clearRect(0, 0, w, h)\n",
        "    let start_time\n",
        "    bench_iters = Math.max(bench_iters, 2)\n",
        "    for (let n = 0; n < bench_iters; n++) {\n",
        "      const bgr = new Uint8Array(h * w * 3)\n",
        "      for (let i = 0; i < bgr.length; i++)\n",
        "        bgr[i] = rgba[(i/3|0)*4 + 2 - i%3]\n",
        "      const result = await teed.run({input: new ort.Tensor(bgr, [1, h, w, 3])})\n",
        "      for (let i = 0; i < result.output.data.length; i++)\n",
        "        rgba_out[i * 4] = rgba_out[i*4 + 1] = rgba_out[i*4 + 2] = result.output.data[i]\n",
        "      if (!n)\n",
        "        start_time = performance.now()\n",
        "    }\n",
        "    stats.textContent = w + 'x' + h + ' ' + ((performance.now()-start_time)/(bench_iters-1)|0) + 'ms/iter'\n",
        "    ctx.putImageData(new ImageData(rgba_out, w, h), 0, 0)\n",
        "  }\n",
        "\n",
        "  img.addEventListener('load', () => predict())\n",
        "  img.src = '/nbextensions/image.jpg'\n",
        "</script>"
      ],
      "metadata": {
        "id": "cjfqSRl9NOMI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
